---
title: Deep Learning Notes (1)
description: 旨在理清深度学习的脉络。
publishDate: 2025-12-09
---

系统地梳理一下**深度学习**这个被炒得热火朝天，但又常常让人望而生畏的领域。

常听人说 GPT、自动驾驶、人脸识别，这些背后的核心技术都是深度学习。但这到底是什么？是魔法吗？不，是统计学、微积分和线性代数的暴力美学。

## 1. 定位：深度学习在哪？

首先来搞清楚它在 AI 版图中的位置。这就像是一个俄罗斯套娃：

-   **人工智能 (Artificial Intelligence)**：最外层，泛指任何让机器展现智慧的技术。
-   **机器学习 (Machine Learning)**：AI 的子集，指让机器从数据中学习规律，而不是手动编写规则。
-   **深度学习 (Deep Learning)**：ML 的子集，特指利用**多层神经网络**来模拟人脑分析学习过程的技术。

>   **一句话总结**：深度学习就是利用**深层的神经网络**，从海量数据中自动提取特征并进行预测的算法。

## 2. 核心构建块：神经元与神经网络

深度学习的灵感虽然来自生物学，但本质上是数学模型。

### 2.1 感知机 (Perceptron)

最基础的单元叫**神经元**（或感知机）。举例来说，决定今晚是否去图书馆复习（输出 y），取决于几个因素（输入 x）：朋友去不去、作业多不多、天气好不好。

每个因素都有一个重要性权重（Weight, w），每个人还有一个基础门槛（Bias, b）。

数学公式其实很简单：
$$
z=\sum_{i=1}^{n}w_ix_i+b
$$

$$
y=σ(z)
$$


其中 σ 是**激活函数 (Activation Function)**。它的作用是引入**非线性**。如果没有它，无论多少层网络叠加，最后都只是一个简单的线性回归，解决不了复杂问题（比如识别猫和狗）。

**常见的激活函数：**

-   **Sigmoid**: 把值压缩到 (0,1) 之间，以前很火，现在容易导致“梯度消失”。
-   **ReLU (Rectified Linear Unit)**: $f(x)=max(0,x)$。目前最常用，简单粗暴，计算快。

### 2.2 多层感知机 (MLP)

把这些神经元像三明治一样叠起来，就成了**深度神经网络 (DNN)**。

-   **输入层 (Input Layer)**: 接收数据（如图片的像素值）。
-   **隐藏层 (Hidden Layers)**: 中间的“黑盒”，负责提取特征。层数越多，“深度”越深。
-   **输出层 (Output Layer)**: 给出预测结果（如概率）。

## 3. 灵魂拷问：机器是怎么“学习”的？

这是初学者最容易晕的地方。其实“学习”的过程，就是**找出一组最优的权重 (w) 和偏置 (b)，让预测结果最接近真实结果**。

这个过程分为三步循环：

### 3.1 前向传播 (Forward Propagation) —— "瞎猜"

数据从输入层流向输出层，经过层层计算，最后给出一个预测值。刚开始权重是随机初始化的，所以预测结果通常是胡说八道。

### 3.2 计算损失 (Loss Function) —— "打分"

我们需要一个公式来衡量刚才猜得有多烂。这个公式叫**损失函数**。 例如均方误差 (MSE)：
$$
L=\frac{1}{N}\sum(y_{pred}-y_{true})^2
$$


L 越小，说明猜得越准。我们的目标就是最小化 L。

### 3.3 反向传播 (Backpropagation) —— "修正"

这是深度学习最天才的地方。 知道了误差 L 后，需要知道**哪一个权重导致了误差**，以及该怎么调整它。 通过**链式法则 (Chain Rule)**，剋从后往前计算误差对每个权重的**梯度 (Gradient)**。

### 3.4 优化器 (Optimizer) —— "下山"

有了梯度，再用**梯度下降法 (Gradient Descent)** 来更新权重：
$$
w_{new}=w_{old}-\alpha\cdot\frac{∂L}{∂w}
$$


这里 α 是**学习率 (Learning Rate)**，决定了我们修正的步子有多大。

-   步子太小：学得太慢。
-   步子太大：容易扯着蛋（震荡，无法收敛）。

>   **总结**：学习 = 前向计算误差 + 反向传播梯度 + 更新权重。重复这个过程几千几万次，模型就“收敛”了。

------

## 4. 深度学习动物园：常见架构

在 CS 领域，不同的问题需要不同的网络结构。

### 4.1 卷积神经网络 (CNN) —— 计算机视觉的王者

如果处理的是图像，全连接网络参数太多了（一张 1000×1000 的图就有 100 万个输入）。CNN 通过**卷积核 (Kernel)** 像扫描仪一样提取局部特征（边缘、纹理）。

-   **关键层**：卷积层 (Conv)、池化层 (Pooling)。
-   **应用**：人脸识别、医学影像分析、自动驾驶。

### 4.2 循环神经网络 (RNN) & LSTM —— 序列数据的专家

如果处理的是文本、语音或股票曲线，前后数据是有联系的。RNN 拥有“记忆”，能把上一步的输出作为下一步的输入。

-   **进阶**：LSTM (长短期记忆网络) 和 GRU 解决了长序列中“忘了开头”的问题。
-   **应用**：机器翻译、语音识别。

### 4.3 Transformer —— 如今的统治者

这是目前最靓的仔。Google 在 2017 年提出《Attention is All You Need》。它抛弃了循环，利用**自注意力机制 (Self-Attention)** 并行处理整个序列。

-   **地位**：它是 BERT、GPT 系列、Llama 等大模型的基石。
-   **特点**：不但能处理文本，现在 (ViT) 也能处理图像。

## 5. 为什么现在才爆发？

神经网络理论上世纪 80 年代就有了，为什么最近十年才起飞？

1.  **大数据 (Big Data)**：互联网提供了海量带标签的数据（Fuel）。
2.  **算力 (GPU)**：NVIDIA 的 GPU 极其擅长矩阵运算，把训练时间从几年缩短到几天（Engine）。
3.  **算法改进**：ReLU 解决了梯度消失，Adam 优化器让收敛更快，Dropout 防止了过拟合。

## 6. 还有什么坑？(Challenges)

这行也不是完美的：

-   **黑盒问题**：我们知道它管用，但很难解释神经元内部具体学到了什么（可解释性差）。
-   **炼丹玄学**：调参（学习率、层数、Batch size）有时候全凭经验和运气。
-   **过拟合 (Overfitting)**：模型在考题（训练集）上满分，实战（测试集）全是零分。

## 7. 入门

-   **入门框架**：**PyTorch** (学术界首选，代码Pythonic，调试方便) 或 **TensorFlow/Keras** (工业界常用)。
-   **必修课**：Andrew Ng (吴恩达) 的 Deep Learning Specialization，或者李沐的《动手学深度学习》。

